{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project\n",
    "This notebook fine-tunes DistilBERT on GLUE/SST-2 and compares baseline and LoRA-adapted models.\n",
    "\n",
    "* PEFT technique: LoRA applied to the attention query/value projections\n",
    "* Model: distilbert-base-uncased with a sequence classification head\n",
    "* Evaluation approach: Hugging Face Trainer with the accuracy metric on the SST-2 validation set\n",
    "* Fine-tuning dataset: GLUE/SST-2 with 1,000 shuffled training samples and the full validation split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f551c63a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:19:48.229722Z",
     "iopub.status.busy": "2025-11-12T11:19:48.229722Z",
     "iopub.status.idle": "2025-11-12T11:19:56.322193Z",
     "shell.execute_reply": "2025-11-12T11:19:56.322193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    get_peft_model,\n",
    "    AutoPeftModelForSequenceClassification,\n",
    ")\n",
    "\n",
    "BASELINE_OUTPUT_DIR = \"/tmp/distilbert-baseline\"\n",
    "PEFT_TRAINING_OUTPUT_DIR = \"/tmp/distilbert-lora\"\n",
    "PEFT_ADAPTER_OUTPUT_DIR = \"/tmp/distilbert-sst2-lora\"\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4935cb4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:19:56.324527Z",
     "iopub.status.busy": "2025-11-12T11:19:56.324527Z",
     "iopub.status.idle": "2025-11-12T11:19:59.035754Z",
     "shell.execute_reply": "2025-11-12T11:19:59.035189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1000\n",
      "Validation samples: 872\n"
     ]
    }
   ],
   "source": [
    "MAX_TRAIN_SAMPLES = 1000\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"sst2\")\n",
    "train_dataset = raw_datasets[\"train\"].shuffle(seed=42).select(range(MAX_TRAIN_SAMPLES))\n",
    "eval_dataset = raw_datasets[\"validation\"]\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(eval_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28c4a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:19:59.036772Z",
     "iopub.status.busy": "2025-11-12T11:19:59.036772Z",
     "iopub.status.idle": "2025-11-12T11:20:00.238058Z",
     "shell.execute_reply": "2025-11-12T11:20:00.238058Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_name)\n",
    "\n",
    "\n",
    "def preprocess_function(batch):\n",
    "    return tokenizer(batch[\"sentence\"], truncation=True)\n",
    "\n",
    "\n",
    "columns_to_remove = [col for col in [\"sentence\", \"idx\"] if col in train_dataset.column_names]\n",
    "train_tokenized = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=columns_to_remove,\n",
    ")\n",
    "columns_to_remove_eval = [col for col in [\"sentence\", \"idx\"] if col in eval_dataset.column_names]\n",
    "eval_tokenized = eval_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=columns_to_remove_eval,\n",
    ")\n",
    "\n",
    "train_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "eval_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019b9f55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:20:00.240313Z",
     "iopub.status.busy": "2025-11-12T11:20:00.240313Z",
     "iopub.status.idle": "2025-11-12T11:20:00.435939Z",
     "shell.execute_reply": "2025-11-12T11:20:00.435939Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Ohara\\AppData\\Local\\Temp\\ipykernel_34360\\3389896621.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  baseline_trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "baseline_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint_name, num_labels=2\n",
    ")\n",
    "\n",
    "baseline_args = TrainingArguments(\n",
    "    output_dir=BASELINE_OUTPUT_DIR,\n",
    "    per_device_eval_batch_size=32,\n",
    "    report_to=\"none\",\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "baseline_trainer = Trainer(\n",
    "    model=baseline_model,\n",
    "    args=baseline_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=eval_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5176b07f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:20:00.438516Z",
     "iopub.status.busy": "2025-11-12T11:20:00.436994Z",
     "iopub.status.idle": "2025-11-12T11:20:13.962284Z",
     "shell.execute_reply": "2025-11-12T11:20:13.961337Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ohara\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline metrics: {'eval_loss': 0.6972277164459229, 'eval_model_preparation_time': 0.0023, 'eval_accuracy': 0.43463302752293576, 'eval_runtime': 15.2714, 'eval_samples_per_second': 57.1, 'eval_steps_per_second': 1.833}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6972277164459229,\n",
       " 'eval_model_preparation_time': 0.0023,\n",
       " 'eval_accuracy': 0.43463302752293576,\n",
       " 'eval_runtime': 15.2714,\n",
       " 'eval_samples_per_second': 57.1,\n",
       " 'eval_steps_per_second': 1.833}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_metrics = baseline_trainer.evaluate()\n",
    "print(\"Baseline metrics:\", baseline_metrics)\n",
    "baseline_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5775fadf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:20:13.964897Z",
     "iopub.status.busy": "2025-11-12T11:20:13.964376Z",
     "iopub.status.idle": "2025-11-12T11:20:14.123220Z",
     "shell.execute_reply": "2025-11-12T11:20:14.122704Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,042 || all params: 67,842,052 || trainable%: 1.3075\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_lin\", \"v_lin\"],\n",
    ")\n",
    "\n",
    "peft_base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint_name, num_labels=2\n",
    ")\n",
    "peft_model = get_peft_model(peft_base_model, lora_config)\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "894046c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:20:14.125821Z",
     "iopub.status.busy": "2025-11-12T11:20:14.125342Z",
     "iopub.status.idle": "2025-11-12T11:20:14.142395Z",
     "shell.execute_reply": "2025-11-12T11:20:14.142395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ohara\\AppData\\Local\\Temp\\ipykernel_34360\\1736226668.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  peft_trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=PEFT_TRAINING_OUTPUT_DIR,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=20,\n",
    "    weight_decay=0.01,\n",
    "    gradient_accumulation_steps=1,\n",
    "    warmup_ratio=0.1,\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=eval_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d4c908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:20:14.145534Z",
     "iopub.status.busy": "2025-11-12T11:20:14.144998Z",
     "iopub.status.idle": "2025-11-12T11:22:51.112883Z",
     "shell.execute_reply": "2025-11-12T11:22:51.112883Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ohara\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 02:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.663300</td>\n",
       "      <td>0.658708</td>\n",
       "      <td>0.510321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.505485</td>\n",
       "      <td>0.822248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.420600</td>\n",
       "      <td>0.434994</td>\n",
       "      <td>0.823394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ohara\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Ohara\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=0.5651135230190539, metrics={'train_runtime': 163.31, 'train_samples_per_second': 18.37, 'train_steps_per_second': 1.157, 'total_flos': 27203244063360.0, 'train_loss': 0.5651135230190539, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_train_result = peft_trainer.train()\n",
    "peft_train_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47abf88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:22:51.113945Z",
     "iopub.status.busy": "2025-11-12T11:22:51.113945Z",
     "iopub.status.idle": "2025-11-12T11:23:05.701460Z",
     "shell.execute_reply": "2025-11-12T11:23:05.700454Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ohara\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned metrics: {'eval_loss': 0.43499407172203064, 'eval_accuracy': 0.823394495412844, 'eval_runtime': 14.578, 'eval_samples_per_second': 59.816, 'eval_steps_per_second': 1.921, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.43499407172203064,\n",
       " 'eval_accuracy': 0.823394495412844,\n",
       " 'eval_runtime': 14.578,\n",
       " 'eval_samples_per_second': 59.816,\n",
       " 'eval_steps_per_second': 1.921,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_metrics = peft_trainer.evaluate()\n",
    "print(\"Fine-tuned metrics:\", finetuned_metrics)\n",
    "finetuned_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "### Storage note\n",
    "\n",
    "All model artifacts are written under /tmp to keep the workspace footprint small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7fe003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:23:05.704088Z",
     "iopub.status.busy": "2025-11-12T11:23:05.702080Z",
     "iopub.status.idle": "2025-11-12T11:23:06.025285Z",
     "shell.execute_reply": "2025-11-12T11:23:06.024174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LoRA adapters and tokenizer to /tmp/distilbert-sst2-lora\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(PEFT_ADAPTER_OUTPUT_DIR, exist_ok=True)\n",
    "peft_model.save_pretrained(PEFT_ADAPTER_OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(PEFT_ADAPTER_OUTPUT_DIR)\n",
    "print(f\"Saved LoRA adapters and tokenizer to {PEFT_ADAPTER_OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "863ec66e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:23:06.026758Z",
     "iopub.status.busy": "2025-11-12T11:23:06.026758Z",
     "iopub.status.idle": "2025-11-12T11:23:06.280837Z",
     "shell.execute_reply": "2025-11-12T11:23:06.280837Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DistilBertForSequenceClassification(\n",
       "      (distilbert): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x TransformerBlock(\n",
       "              (attention): DistilBertSdpaAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pre_classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    PEFT_ADAPTER_OUTPUT_DIR\n",
    ")\n",
    "reloaded_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc3a8147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:23:06.283136Z",
     "iopub.status.busy": "2025-11-12T11:23:06.283136Z",
     "iopub.status.idle": "2025-11-12T11:23:20.705624Z",
     "shell.execute_reply": "2025-11-12T11:23:20.704579Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ohara\\AppData\\Local\\Temp\\ipykernel_38952\\1193637221.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  reloaded_trainer = Trainer(\n",
      "C:\\Users\\Ohara\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.43499407172203064,\n",
       " 'eval_model_preparation_time': 0.0022,\n",
       " 'eval_accuracy': 0.823394495412844,\n",
       " 'eval_runtime': 14.3972,\n",
       " 'eval_samples_per_second': 60.567,\n",
       " 'eval_steps_per_second': 1.945}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_eval_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/distilbert-lora-eval\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "reloaded_trainer = Trainer(\n",
    "    model=reloaded_model,\n",
    "    args=peft_eval_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=eval_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "reloaded_metrics = reloaded_trainer.evaluate()\n",
    "reloaded_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc96905a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:23:20.707708Z",
     "iopub.status.busy": "2025-11-12T11:23:20.707708Z",
     "iopub.status.idle": "2025-11-12T11:23:20.713540Z",
     "shell.execute_reply": "2025-11-12T11:23:20.713024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.4346\n",
      "LoRA accuracy: 0.8234\n",
      "Absolute improvement: 0.3888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'baseline': {'eval_loss': 0.6972277164459229,\n",
       "  'eval_model_preparation_time': 0.0023,\n",
       "  'eval_accuracy': 0.43463302752293576,\n",
       "  'eval_runtime': 13.5136,\n",
       "  'eval_samples_per_second': 64.528,\n",
       "  'eval_steps_per_second': 2.072},\n",
       " 'lora': {'eval_loss': 0.43499407172203064,\n",
       "  'eval_model_preparation_time': 0.0022,\n",
       "  'eval_accuracy': 0.823394495412844,\n",
       "  'eval_runtime': 14.3972,\n",
       "  'eval_samples_per_second': 60.567,\n",
       "  'eval_steps_per_second': 1.945}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_acc = baseline_metrics[\"eval_accuracy\"]\n",
    "lora_acc = reloaded_metrics[\"eval_accuracy\"]\n",
    "print(f\"Baseline accuracy: {baseline_acc:.4f}\")\n",
    "print(f\"LoRA accuracy: {lora_acc:.4f}\")\n",
    "print(f\"Absolute improvement: {lora_acc - baseline_acc:.4f}\")\n",
    "{\"baseline\": baseline_metrics, \"lora\": reloaded_metrics}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "866ab28c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:23:20.715747Z",
     "iopub.status.busy": "2025-11-12T11:23:20.715228Z",
     "iopub.status.idle": "2025-11-12T11:23:20.772104Z",
     "shell.execute_reply": "2025-11-12T11:23:20.771100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The movie was unexpectedly delightful and heartwarming.\n",
      "Predicted label: positive\n",
      "----------------------------------------\n",
      "Text: The plot was incoherent and the acting was terrible.\n",
      "Predicted label: negative\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "label_names = raw_datasets[\"train\"].features[\"label\"].names\n",
    "sample_sentences = [\n",
    "    \"The movie was unexpectedly delightful and heartwarming.\",\n",
    "    \"The plot was incoherent and the acting was terrible.\",\n",
    "]\n",
    "\n",
    "reloaded_model.eval()\n",
    "for text in sample_sentences:\n",
    "    encoded = tokenizer(text, return_tensors=\"pt\")\n",
    "    encoded = {k: v.to(reloaded_model.device) for k, v in encoded.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = reloaded_model(**encoded)\n",
    "        prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted label: {label_names[prediction]}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9a32e4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:23:20.774122Z",
     "iopub.status.busy": "2025-11-12T11:23:20.774122Z",
     "iopub.status.idle": "2025-11-12T11:23:20.778634Z",
     "shell.execute_reply": "2025-11-12T11:23:20.778634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adapter_config.json',\n",
       " 'adapter_model.safetensors',\n",
       " 'README.md',\n",
       " 'special_tokens_map.json',\n",
       " 'tokenizer.json',\n",
       " 'tokenizer_config.json',\n",
       " 'vocab.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(PEFT_ADAPTER_OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf9d0b",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "LoRA fine-tuning on the 1k-sample SST-2 subset improved DistilBERT accuracy from **0.43** to **0.82**, with the adapter weights stored in `distilbert-sst2-lora/`. Training was completed on CPU, so expect ~15 minutes per run.\n",
    "\n",
    "Next steps if you revisit the project:\n",
    "- Try a larger training subset or extra epochs to squeeze out a few more points.\n",
    "- Experiment with QLoRA or gradient checkpointing to reduce memory while exploring bigger models.\n",
    "- Add metrics like F1 or MCC if you want richer comparisons for imbalanced datasets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03200c6149bb401589b863f39ed6e386": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ce824be2765437d99fba4ed92d1e4dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2af64de4bb844f2c83a8e4ea5fbec89c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2c5b465650fb46788fa80213f34e753a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3158a579938342b7a1da6474552e6534": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33e9552a943a428d9ec6f873de88451e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5c36386d0ed44f9da0e0cb7c3d37574e",
       "placeholder": "​",
       "style": "IPY_MODEL_2c5b465650fb46788fa80213f34e753a",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "4eb50992d237461b8ef143f34ff06134": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3158a579938342b7a1da6474552e6534",
       "max": 872,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2af64de4bb844f2c83a8e4ea5fbec89c",
       "tabbable": null,
       "tooltip": null,
       "value": 872
      }
     },
     "5c36386d0ed44f9da0e0cb7c3d37574e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b229d3f31a449a29d423660e7b34884": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_33e9552a943a428d9ec6f873de88451e",
        "IPY_MODEL_4eb50992d237461b8ef143f34ff06134",
        "IPY_MODEL_c37d37f3a5c54cdeaec00b4c5033da0e"
       ],
       "layout": "IPY_MODEL_03200c6149bb401589b863f39ed6e386",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c37d37f3a5c54cdeaec00b4c5033da0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1ce824be2765437d99fba4ed92d1e4dd",
       "placeholder": "​",
       "style": "IPY_MODEL_e3bf6d505f7644eb93ec157b8465f680",
       "tabbable": null,
       "tooltip": null,
       "value": " 872/872 [00:00&lt;00:00, 20657.39 examples/s]"
      }
     },
     "e3bf6d505f7644eb93ec157b8465f680": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
